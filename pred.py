# -*- coding: utf-8 -*-
"""pred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W96xqlk5uPIYzd7cndm71SGIgNeevwnW
"""

import pandas as pd

df = pd.read_csv("data.csv")

from sklearn.preprocessing import LabelEncoder

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import MultinomialNB

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

rfc = RandomForestClassifier(random_state=1)
logr = LogisticRegression(random_state=0)
gbc = GradientBoostingClassifier(n_estimators=10)
dtc = DecisionTreeClassifier(random_state=0)
nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=0)
nb = MultinomialNB()

# df=df.drop('Country',axis=1)
x=df.drop('City',axis=1)
# x = x.drop('PM2.5 AQI Category')
y=df['AQI Category']
# print(y)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

# le.fit(x['City'])
# x['City']=le.fit_transform(x['City'])

le.fit(x['AQI Category'])
x['AQI Category']=le.fit_transform(x['AQI Category'])

# le.fit(x['CO AQI Category'])
# x['CO AQI Category']=le.fit_transform(x['CO AQI Category'])

# le.fit(x['Ozone AQI Category'])
# x['Ozone AQI Category']=le.fit_transform(x['Ozone AQI Category'])

# le.fit(x['NO2 AQI Category'])
# x['NO2 AQI Category']=le.fit_transform(x['NO2 AQI Category'])

# le.fit(x['PM2.5 AQI Category'])
# x['PM2.5 AQI Category']=le.fit_transform(['])
# y = y.drop[0]
# print(y)

x_train,x_test,y_train,y_test =train_test_split(x,y,random_state=0,test_size=0.3)

# rfc.fit(x_train,y_train)
# y_rfc=rfc.predict(x_test)

# logr.fit(x_train,y_train)
# y_logr=logr.predict(x_test)

gbc.fit(x_train,y_train)
y_gbc=gbc.predict(x_test)
print(x_test)


value = gbc.predict([[40,1,1,40,0,32]])
print(value)

# dtc.fit(x_train,y_train)
# y_dtc=dtc.predict(x_test)

# # svm.fit(x_train,y_train)
# # y_svm=svm.predict(x_test)

# nn.fit(x_train,y_train)
# y_nn=nn.predict(x_test)

# nb.fit(x_train,y_train)
# y_nb=nb.predict(x_test)

# print("Random Forest:", accuracy_score(y_test,y_rfc))
# print("Logistic Regression:", accuracy_score(y_test,y_logr))
print("Gradient Boosting:", accuracy_score(y_test,y_gbc))
# print("Decision Tree:", accuracy_score(y_test,y_dtc))
# # print("Artificial Neural Network:", accuracy_score(y_test,y_nn))
# print("Naive Bayes:", accuracy_score(y_test,y_nb))

import joblib

filename = 'model.pkl'
joblib.dump(y_gbc, filename)

import pickle
pickle.dump(gbc,open('model.pkl','wb'))